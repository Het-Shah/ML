{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import torch\n",
    "import codecs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMNIST(data.Dataset):\n",
    "    \n",
    "    \"\"\"`Fashion-MNIST <https://github.com/zalandoresearch/fashion-mnist>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where ``processed/training.pt``\n",
    "            and  ``processed/test.pt`` exist.\n",
    "        train (bool, optional): If True, creates dataset from ``training.pt``,\n",
    "            otherwise from ``test.pt``.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "    \"\"\"\n",
    "    \n",
    "    urls =[\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz',\n",
    "    ]\n",
    "    raw_folder = 'raw'\n",
    "    processed_folder = 'processed'\n",
    "    training_file = 'training.pt'\n",
    "    test_file = 'test.pt'\n",
    "    \n",
    "    def __init__(self, root,train=True, transform=None, target_transform=None, download=False):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train\n",
    "        \n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError('Dataset not found use download=True to download it')\n",
    "\n",
    "        if self.train:\n",
    "            self.train_data, self.train_labels = torch.load(\n",
    "                os.path.join(root, self.processed_folder, self.training_file))\n",
    "        else:\n",
    "            self.test_data, self.test_labels = torch.load(os.path.join(root, self.processed_folder, self.test_file))\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "        \n",
    "    def _check_exists(self):\n",
    "        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
    "    \n",
    "    def download(self):\n",
    "        \"\"\"Download the FMNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
    "        from six.moves import urllib\n",
    "        import gzip\n",
    "\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        # download files\n",
    "        try:\n",
    "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
    "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
    "        except OSError as e:\n",
    "            if e.errno == errno.EEXIST:\n",
    "                pass\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        for url in self.urls:\n",
    "            print('Downloading ' + url)\n",
    "            data = urllib.request.urlopen(url)\n",
    "            filename = url.rpartition('/')[2]\n",
    "            file_path = os.path.join(self.root, self.raw_folder, filename)\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(data.read())\n",
    "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
    "                    gzip.GzipFile(file_path) as zip_f:\n",
    "                out_f.write(zip_f.read())\n",
    "            os.unlink(file_path)\n",
    "\n",
    "        # process and save as torch files\n",
    "        print('Processing...')\n",
    "\n",
    "        training_set = (\n",
    "            read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
    "        )\n",
    "        test_set = (\n",
    "            read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
    "        )\n",
    "        with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
    "            torch.save(training_set, f)\n",
    "        with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
    "            torch.save(test_set, f)\n",
    "\n",
    "        print('Done!')\n",
    "        \n",
    "    def get_int(b):\n",
    "        return int(codecs.encode(b, 'hex'), 16)\n",
    "\n",
    "    def parse_byte(b):\n",
    "        if isinstance(b, str):\n",
    "            return ord(b)\n",
    "        return b\n",
    "\n",
    "    def read_label_file(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            data = f.read()\n",
    "            assert get_int(data[:4]) == 2049\n",
    "            length = get_int(data[4:8])\n",
    "            labels = [parse_byte(b) for b in data[8:]]\n",
    "            assert len(labels) == length\n",
    "            return torch.LongTensor(labels)\n",
    "\n",
    "    def read_image_file(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            data = f.read()\n",
    "            assert get_int(data[:4]) == 2051\n",
    "            length = get_int(data[4:8])\n",
    "            num_rows = get_int(data[8:12])\n",
    "            num_cols = get_int(data[12:16])\n",
    "            images = []\n",
    "            idx = 16\n",
    "            for l in range(length):\n",
    "                img = []\n",
    "                images.append(img)\n",
    "                for r in range(num_rows):\n",
    "                    row = []\n",
    "                    img.append(row)\n",
    "                    for c in range(num_cols):\n",
    "                        row.append(parse_byte(data[idx]))\n",
    "                        idx += 1\n",
    "            assert len(images) == length\n",
    "            return torch.ByteTensor(images).view(-1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "fmnist_trainset = FMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "fmnist_testset = FMNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.FMNIST object at 0x7fbbc31304a8>\n",
      "<__main__.FMNIST object at 0x7fbbc3130630>\n"
     ]
    }
   ],
   "source": [
    "print(fmnist_trainset)\n",
    "print(fmnist_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> total trainning batch number: 600\n",
      "==>>> total testing batch number: 100\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=fmnist_trainset,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=fmnist_testset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False)\n",
    "\n",
    "print('==>>> total trainning batch number: {}'.format(len(train_loader)))\n",
    "print('==>>> total testing batch number: {}'.format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,20,5,1)\n",
    "        self.conv2 = nn.Conv2d(20,50,5,1)\n",
    "        self.fc1 = nn.Linear(4*4*50,500)\n",
    "        self.fc2 = nn.Linear(500,10)\n",
    "    def forward(self, y):\n",
    "        y = F.relu(self.conv1(y))\n",
    "        y = F.max_pool2d(y, 2, 2)\n",
    "        y = F.relu(self.conv2(y))\n",
    "        y = F.max_pool2d(y, 2, 2)\n",
    "        y = y.view(-1, 4*4*50)\n",
    "        y = F.relu(self.fc1(y))\n",
    "        y = self.fc2(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train loss: 0.26372596621513367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/het/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 test loss: 0.37559249997138977 acc: 87\n",
      "epoch: 2 train loss: 0.16733808815479279\n",
      "epoch: 2 test loss: 0.30838537216186523 acc: 88\n",
      "epoch: 3 train loss: 0.16979366540908813\n",
      "epoch: 3 test loss: 0.2317211776971817 acc: 89\n",
      "epoch: 4 train loss: 0.14462095499038696\n",
      "epoch: 4 test loss: 0.29656627774238586 acc: 89\n",
      "epoch: 5 train loss: 0.157267764210701\n",
      "epoch: 5 test loss: 0.28530892729759216 acc: 90\n",
      "epoch: 6 train loss: 0.14537476003170013\n",
      "epoch: 6 test loss: 0.29633498191833496 acc: 90\n",
      "epoch: 7 train loss: 0.213612899184227\n",
      "epoch: 7 test loss: 0.2619575262069702 acc: 90\n",
      "epoch: 8 train loss: 0.179270401597023\n",
      "epoch: 8 test loss: 0.2631705403327942 acc: 91\n",
      "epoch: 9 train loss: 0.05928034335374832\n",
      "epoch: 9 test loss: 0.2637607455253601 acc: 90\n",
      "epoch: 10 train loss: 0.05857496336102486\n",
      "epoch: 10 test loss: 0.30860772728919983 acc: 90\n",
      "epoch: 11 train loss: 0.11295216530561447\n",
      "epoch: 11 test loss: 0.37029018998146057 acc: 91\n",
      "epoch: 12 train loss: 0.057852067053318024\n",
      "epoch: 12 test loss: 0.3151828646659851 acc: 91\n",
      "epoch: 13 train loss: 0.09571573138237\n",
      "epoch: 13 test loss: 0.3531095087528229 acc: 91\n",
      "epoch: 14 train loss: 0.07222284376621246\n",
      "epoch: 14 test loss: 0.32478535175323486 acc: 90\n"
     ]
    }
   ],
   "source": [
    "train_loss_history = []\n",
    "for epoch in range(20):\n",
    "    # training\n",
    "    ave_loss = 0\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        optimiser.zero_grad()\n",
    "        x, target = Variable(x), Variable(target)\n",
    "        out = model(x)\n",
    "#         print(out.shape)\n",
    "#         print(target.shape)\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        train_loss_history.append(loss)\n",
    "        optimiser.step()\n",
    "        if (batch_idx+1) % 600 == 0 or (batch_idx+1) == len(train_loader):\n",
    "            print('epoch: '+str(epoch+1)+' train loss: '+str(loss.item()))\n",
    "    # testing\n",
    "    correct_cnt, ave_loss = 0, 0\n",
    "    total_cnt = 0\n",
    "    for batch_idx, (x, target) in enumerate(test_loader):\n",
    "        x, target = Variable(x, volatile=True), Variable(target, volatile=True)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, target)\n",
    "        _, pred_label = torch.max(out.data, 1)\n",
    "        total_cnt += x.data.size()[0]\n",
    "#         total_cnt += 100\n",
    "#         print('Prediction: {}'.format(pred_label))\n",
    "#         print(\"Target: {}\".format(target.data))\n",
    "        correct_cnt += (pred_label == target.data).sum()\n",
    "#         print(\"Correct_cnt: {}\".format(correct_cnt))\n",
    "        acc = (100.0 * correct_cnt) / (total_cnt)\n",
    "        if(batch_idx+1) % 100 == 0 or (batch_idx+1) == len(test_loader):\n",
    "            print('epoch: '+str(epoch+1)+' test loss: '+str(loss.item())+' acc: '+str(acc.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Training loss')\n",
    "plt.plot(train_loss_history, 'o')\n",
    "plt.xlabel('Iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
